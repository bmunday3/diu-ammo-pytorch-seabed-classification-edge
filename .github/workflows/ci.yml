name: Build

on:
  push:
    paths:
      ['model_info.json']

jobs:
  build:
    name: Build Container and Publish to Modzy
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - uses: actions/setup-python@v2
      with:
        python-version: '3.9'
        cache: 'pip'
    - run: pip install -r requirements.txt
    - name: Invoke Chassis Service
      env: 
        DOCKER_USER: ${{ secrets.DOCKER_USER }}
        DOCKER_PASS: ${{ secrets.DOCKER_PASS }}
        MODZY_URL: ${{ secrets.MODZY_URL }}
        MODZY_API_KEY: ${{ secrets.MODZY_API_KEY }}
        CHASSIS_SERVICE: ${{ secrets.CHASSIS_SERVICE }}
      run: |
        import chassisml
        import sys
        import copy
        import numpy as np
        import time
        import io
        import os
        import requests

        import torch
        import torch.nn as nn
        import torchvision.transforms as transforms
        import torchvision.models as models

        from PIL import Image

        chassis_creds = {
            "dockerhub_user": os.getenv("DOCKER_USER"),
            "dockerhub_pass": os.getenv("DOCKER_PASS"),
            "modzy_url": os.getenv("MODZY_URL"),
            "modzy_api_key": os.getenv("MODZY_API_KEY"),
        }

        # load model and other required artifacts
        pxls = 150

        classes = ["plane", "empty seafloor", "ship"]

        transform = transforms.Compose([ 
            transforms.Resize(size=(pxls,pxls)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])
        ])        

        with open("model_info.json", "r") as model_file:
            model_info = json.load(model_file)
        
        # Load pretrained ResNet50 Model
        model = models.resnet50()

        # Freeze model parameters
        for param in model.parameters():
            param.requires_grad = False

        # Modify the final layer
        fc_inputs = model.fc.in_features
        model.fc = nn.Sequential(
            nn.Linear(fc_inputs, 256),
            nn.ReLU(),
            nn.Linear(256, 3)
        )

        model.load_state_dict(torch.load(model_info["weightsFilePath"], map_location=torch.device('cpu')))
        with torch.no_grad():
            model.eval()        

        # transform into process function
        def process(input_bytes):
            # preprocess image
            decoded = Image.open(io.BytesIO(input_bytes)).convert('RGB')
            img_t = transform(decoded)
            img_t = img_t.reshape(1, 3, pxls, pxls)
            
            # run inference, apply softmax, process outputs
            preds = model(img_t)
            probs = torch.nn.functional.softmax(preds, dim=1)[0]
            _, indices = torch.sort(preds, descending=True)
            inference_result = {
                "classPredictions": [
                    {"class": classes[idx.item()], "score": round(probs[idx].item(), 3)}
                for idx in indices[0]]
            }
            
            structured_output = {
                "data": {
                    "result": inference_result,
                    "explanation": None,
                    "drift": None,
                }
            }    
            
            return structured_output

        chassis_client = chassisml.ChassisClient(os.getenv("CHASSIS_SERVICE"))
        chassis_model = chassis_client.create_model(process_fn=process)

        try:
          results = chassis_model.test(model_info["sampleDataFilePath"])
          print(results)
        except Exception as e:
          raise ValueError("Error testing model: {}".format(e))

        response = chassis_model.publish(
          model_name=model_info["name"],
          model_version=model_info["version"],
          registry_user=chassis_creds["dockerhub_user"],
          registry_pass=chassis_creds["dockerhub_pass"],
          modzy_url=chassis_creds["modzy_url"],
          modzy_api_key=chassis_creds["modzy_api_key"],
          modzy_sample_input_path=model_info["sampleDataFilePath"]
        )

        time.sleep(5)
        
        print(response.get('job_id'))

        final_status = chassis_client.block_until_complete(response.get('job_id'))
        print(final_status)

        if not (final_status["status"]["failed"] is None and final_status["status"]["conditions"][0]["type"] == "Complete"):
          raise ValueError("Error publishing model (See details above)") 

        # create environment variables for MODEL_ID and model_version
        MODEL_ID = final_status["result"]["model"]["modelId"]
        MODEL_VERSION = final_status["result"]["version"]

        # patch docs
        # MODEL_ID = os.getenv("MODEL_ID")
        # MODEL_VERSION = os.getenv("MODEL_VERSION")

        # # load model info file to be accessed in tech documentation patching
        # with open("model_info.json", "r") as model_file:
        #     model_info = json.load(model_file)

        # assign corrrect URL to patch model
        url = "{}/api/models/{}/versions/{}".format(chassis_creds["modzy_url"], MODEL_ID, MODEL_VERSION)

        payload = {
            "inputs": model_info["technicalDetails"]["inputs"],
            "outputs": model_info["technicalDetails"]["outputs"],    
            "statistics": model_info["technicalDetails"]["statistics"],
            "processing": {
                "minimumParallelCapacity": 0,
                "maximumParallelCapacity": 1
            },
            "longDescription": model_info["technicalDetails"]["longDescription"],
            "technicalDetails": model_info["technicalDetails"]["techDetails"],
            "performanceSummary": model_info["technicalDetails"]["performanceSummary"]
        }

        headers = {
            "Accept": "application/json",
            "Content-Type": "application/json",
            "Authorization": "ApiKey {}".format(chassis_creds["modzy_api_key"])
        }

        response = requests.patch(url, json=payload, headers=headers)
        print(response.text)        
      shell: python
  # add-docs:
  #   name: Add Custom Documentation to Newly Deployed Model
  #   runs-on: ubuntu-latest
  #   steps:
  #   - uses: actions/checkout@v2
  #   - uses: actions/setup-python@v2
  #     with:
  #       python-version: '3.9'
  #       cache: 'pip'
  #   - run: pip install -r requirements.txt
  #   - name: Invoke Chassis Service
  #     env: 
  #       MODZY_URL: ${{ secrets.MODZY_URL }}
  #       MODZY_API_KEY: ${{ secrets.MODZY_API_KEY }}
  #     run: |
  #       import os, requests
  #       MODEL_ID = os.getenv("MODEL_ID")
  #       MODEL_VERSION = os.getenv("MODEL_VERSION")

  #       # load model info file to be accessed in tech documentation patching
  #       with open("model_info.json", "r") as model_file:
  #           model_info = json.load(model_file)

  #       # assign corrrect URL to patch model
  #       url = "{}/api/models/{}/versions/{}".format(os.getenv("MODZY_URL"), MODEL_ID, MODEL_VERSION)

  #       payload = {
  #           "inputs": model_info["technicalDetails"]["inputs"],
  #           "outputs": model_info["technicalDetails"]["outputs"],    
  #           "statistics": model_info["technicalDetails"]["statistics"],
  #           "processing": {
  #               "minimumParallelCapacity": 0,
  #               "maximumParallelCapacity": 1
  #           },
  #           "longDescription": model_info["technicalDetails"]["longDescription"],
  #           "technicalDetails": model_info["technicalDetails"]["techDetails"],
  #           "performanceSummary": model_info["technicalDetails"]["performanceSummary"]
  #       }

  #       headers = {
  #           "Accept": "application/json",
  #           "Content-Type": "application/json",
  #           "Authorization": "ApiKey {}".format(os.getenv("MODZY_API_KEY"))
  #       }

  #       response = requests.patch(url, json=payload, headers=headers)   
  #     shell: python          

            
          

